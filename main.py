from pathlib import Path
import yaml
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate
from langchain.output_parsers import StrOutputParser

# ====== ç¡®è®¤JDå†…å®¹ ======
# TODO

# ====== ç”¨æˆ·è¾“å…¥ ======
print("=== Entry Sheetç”Ÿæˆ Agent ===")
es_question = input("ğŸ“Œ è¯·è¾“å…¥ESé—®é¢˜ï¼š\n> ")

# ====== åŠ è½½ç”¨æˆ· profile ======
with open("data/user_profile.yaml", encoding="utf-8") as f:
    user_profile = yaml.safe_load(f)

# ====== åŠ è½½æ¨¡æ¿ prompt ======
prompt_template = Path("prompts/es_template.txt").read_text(encoding="utf-8")
prompt = ChatPromptTemplate.from_template(prompt_template)

# ====== LLM Modelï¼ˆä½ å¯ä»¥æ¢æˆ GPT-4 ç­‰ï¼‰ ======
llm = ChatOpenAI(model="gpt-4o", temperature=0.7)

# ====== æ„å»ºé“¾æ¡ ======
chain = prompt | llm | StrOutputParser()

# ====== æ„å»ºå¡«å…¥å†…å®¹ ======
lang_choice = input("ğŸŒ è¯·é€‰æ‹©è¾“å‡ºè¯­è¨€ï¼ˆja / enï¼‰ï¼š\n> ") or "ja"
output_limitation = input("  æ˜¯å¦æœ‰å­—æ•°é™åˆ¶ï¼Ÿ (é»˜è®¤ä¸ºæ²¡æœ‰)") or "No limitation"

# NOTE: è¿™é‡Œæˆ‘ä»¬æ¨¡æ‹Ÿ user_profile çš„å­—ç¬¦ä¸²å½¢å¼ï¼Œæœªæ¥å¯ä»¥æ¢æˆæ›´ç²¾ç»†çš„å­—æ®µé€‰æ‹©
profile_text = f"""
æ°å: {user_profile['name']}
å­¦æ ¡: {user_profile['school']}
å­¦ä½: {user_profile['degree']}ï¼ˆ{user_profile['graduation_year']}å¹´å’æ¥­äºˆå®šï¼‰
ã‚¹ã‚­ãƒ«: {', '.join(user_profile['skills'])}
æ¦‚è¦: {user_profile['summary']}

ä¸»ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ:
"""
for proj in user_profile['projects']:
    profile_text += f"- {proj['title']}ï¼ˆ{proj['duration']}ï¼‰: {proj['description']}\n"



# ====== è¿è¡Œ Agent ======
result = chain.invoke({
    "user_profile": profile_text.strip(),
    "es_question": es_question.strip(),
    "language": lang_choice.strip(),
    "output_limitation": output_limitation.strip(),
})

print("\n=== âœ¨ ç”Ÿæˆçš„ESè‰æ¡ˆï¼š===\n")
print(result.strip())
